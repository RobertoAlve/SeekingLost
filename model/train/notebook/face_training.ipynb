{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "000d2715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "\n",
    "s3 = session.client('s3')\n",
    "local_dir = './images'\n",
    "bucket_name = 'seekinglost-dados-treino-raw'\n",
    "response = s3.list_objects_v2(Bucket=bucket_name, Prefix='timothée_chalamet/')\n",
    "\n",
    "user_count = 0\n",
    "image_count_start = 10\n",
    "current_prefix = None\n",
    "names = [\"\"]\n",
    "\n",
    "if 'Contents' in response:\n",
    "    for item in response['Contents']:\n",
    "        file_name = item['Key']\n",
    "\n",
    "        prefix = file_name.split('/')[0]\n",
    "\n",
    "        if prefix != current_prefix:\n",
    "            current_prefix = prefix\n",
    "            user_count += 1\n",
    "            user_image_count = 10\n",
    "            user_image_count = image_count_start\n",
    "            names.append(prefix)\n",
    "\n",
    "        \n",
    "        # Define o caminho completo para o arquivo de destino\n",
    "        destination_path = os.path.join(local_dir, f\"User.{user_count}.{user_image_count}.jpg\")\n",
    "        \n",
    "        # Cria diretórios se não existirem\n",
    "        os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n",
    "        \n",
    "        # Baixa o arquivo\n",
    "        s3.download_file(bucket_name, file_name, destination_path)\n",
    "        \n",
    "        print(f\"Arquivo {file_name} baixado para {destination_path}\")\n",
    "        user_image_count += 1\n",
    "else:\n",
    "    print(\"O bucket está vazio ou não contém arquivos.\")\n",
    "\n",
    "print(\"Download concluído.\")\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bac28dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído. As imagens processadas foram salvas em: processed_images\n"
     ]
    }
   ],
   "source": [
    "input_path = 'images'\n",
    "output_path = 'processed_images'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "def resize_face(image, face_coordinates):\n",
    "    x, y, w, h = face_coordinates\n",
    "    face_roi = image[y:y+h, x:x+w]\n",
    "    resized_face = cv2.resize(face_roi, (100, 100))\n",
    "    return resized_face\n",
    "\n",
    "\n",
    "def resize_face_with_margin(image, face_coordinates, margin):\n",
    "    x, y, w, h = face_coordinates\n",
    "\n",
    "    x -= margin\n",
    "    y -= margin\n",
    "    w += 2 * margin\n",
    "    h += 2 * margin\n",
    "\n",
    "    x = max(0, x)\n",
    "    y = max(0, y)\n",
    "\n",
    "    w = min(w, image.shape[1] - x)\n",
    "    h = min(h, image.shape[0] - y)\n",
    "\n",
    "    face_roi = image[y:y+h, x:x+w]\n",
    "    resized_face = cv2.resize(face_roi, (260, 260))\n",
    "    return resized_face\n",
    "\n",
    "\n",
    "for filename in os.listdir(input_path):\n",
    "    input_image_path = os.path.join(input_path, filename)\n",
    "    image = cv2.imread(input_image_path)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    equalized_gray_image = cv2.equalizeHist(gray_image)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray_image,\n",
    "        scaleFactor=1.5,\n",
    "        minNeighbors=8,\n",
    "        minSize=(30, 30)\n",
    "        )\n",
    "\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        resized_face = resize_face_with_margin(gray_image, (x, y, w, h), margin=80)\n",
    "        output_filename = f\"{os.path.splitext(filename)[0]}_face_{i}.png\"\n",
    "        output_image_path = os.path.join(output_path, output_filename)\n",
    "\n",
    "        cv2.imwrite(output_image_path, resized_face)\n",
    "\n",
    "        \n",
    "print(\"Processamento concluído. As imagens processadas foram salvas em:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d20ac23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando modelo...\n",
      "1 rostos treinados.\n"
     ]
    }
   ],
   "source": [
    "path = 'processed_images'\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def trainingModel(path):\n",
    "    paths = [os.path.join(path, f) for f in os.listdir(path)]     \n",
    "    faceSamples = []\n",
    "    ids = []\n",
    "\n",
    "    for imagePath in paths:\n",
    "        PIL_img = Image.open(imagePath).convert('L')\n",
    "        img_uint8 = np.array(PIL_img, 'uint8')\n",
    "\n",
    "        id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        faces = detector.detectMultiScale(img_uint8)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            faceSamples.append(img_uint8[y:y+h, x:x+w])\n",
    "            ids.append(id)\n",
    "\n",
    "    return faceSamples, ids\n",
    "\n",
    "print (\"Treinando modelo...\")\n",
    "faces, ids = trainingModel(path)\n",
    "recognizer.train(faces, np.array(ids))\n",
    "\n",
    "recognizer.write('trainer/trainer.yml')\n",
    "\n",
    "print(\"{0} rostos treinados.\".format(len(np.unique(ids))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6208baa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook face_training.ipynb to script\n",
      "[NbConvertApp] Writing 4938 bytes to face_training.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script face_training.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c9954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
